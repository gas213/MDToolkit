#!/bin/sh

# From MDToolkit template file: sol.sh

# === README ===
# This script is designed to be submitted from inside a user-created, run-specific directory in a "home-like" space (backed up, or intended to be backed up). The directory should only contain:
#   - This script
#   - The LAMMPS input file for the run
#   - Any data/restart file(s) required for the run to begin - make sure these are backed up somewhere else! They will be moved into the scratch-like space, not copied.
# The script will create an identical directory structure at the SCRATCH_DIR location, which is where dump/restart files will be generated.
# Any .txt files generated by LAMMPS via fix commands should be automatically copied back to the home-like space after the run (unless the job exceeds its time limit).
# However, the LAMMPS log file will be generated directly on the home-like space.
# If the simulation runs to completion, the only action that should be required is to back up any dump/restart files that you want from the SCRATCH_DIR space.



# vvv REPLACE THE {{FIELDS}} vvv

# Partitions info:
# rapids: max 3 days, 64 CPUs per node
# hawkcpu: max 3 days, 50 CPUs per node
# rapids-express: max 2 hours, max 6 CPUs
# hawkcpu-express: max 6 hours, max 6 CPUs

#SBATCH --partition={{rapids, hawkcpu, rapids-express, hawkcpu-express}}
#SBATCH --time={{d-hh:mm:ss}}
#SBATCH --nodes={{n}}
#SBATCH --ntasks-per-node={{64, 50, 6}}
#SBATCH --job-name={{name}}
#SBATCH --output="job.%j.%N.out"
#SBATCH --mail-type=ALL
#SBATCH --mail-user={{email}}

# The name of our group's ceph allocation directory
ALLOCATION=ebw210_093025

# User's scratch-like directory where dumps and restarts will be generated; must end with a forward slash /
SCRATCH_DIR=$HOME/$ALLOCATION/$USER/{{dir}}/



# The rest of this should be automatic

RUN_DIR_HOME="$PWD/"
RUN_DIR_RELATIVE="${PWD##$HOME/$ALLOCATION/$USER/}/"
RUN_DIR_SCRATCH="$SCRATCH_DIR$RUN_DIR_RELATIVE"

# Prevent overwriting an existing run by checking if there is already a directory in the scratch-like space with the same name
if [ -d $RUN_DIR_SCRATCH ]; then
    echo "ERROR Scratch-like run directory already exists: $RUN_DIR_SCRATCH"
    exit 1
# Make sure there is exactly one LAMMPS input file for this run
elif [ $(find $RUN_DIR_HOME -name "*.in" | wc -l) -ne 1 ]; then
    echo "ERROR There must be exactly one .in file in the home run directory."
    exit 1
fi

IN_PATH_HOME=$(find $RUN_DIR_HOME -name "*.in")
IN_PATH_RELATIVE=${IN_PATH_HOME##$RUN_DIR_HOME}

# Create identical run directory structure on the scratch-like space, copy LAMMPS input file there and move any data/restart files there
mkdir -p $RUN_DIR_SCRATCH
cp $IN_PATH_RELATIVE $RUN_DIR_SCRATCH
if [ $(find $RUN_DIR_HOME -name "*.data" | wc -l) -gt 0 ]; then
    mv *.data $RUN_DIR_SCRATCH
fi
if [ $(find $RUN_DIR_HOME -name "*.restart" | wc -l) -gt 0 ]; then
    mv *.restart $RUN_DIR_SCRATCH
fi
if [ $(find $RUN_DIR_HOME -name "*.rs" | wc -l) -gt 0 ]; then
    mv *.rs $RUN_DIR_SCRATCH
fi

# Switch to the new run directory on the scratch-like space and start the run
# Write LAMMPS log to the home-like space
cd $RUN_DIR_SCRATCH
module purge
module load gcc/12.4.0
module load openmpi/5.0.5
module load lammps/20240829.1
mpirun -np $SLURM_NTASKS `which lmp` -in $IN_PATH_RELATIVE -log "${RUN_DIR_HOME}log.lammps"

# After the run, copy any txt files generated by LAMMPS back to the home-like space
if [ $(find $RUN_DIR_SCRATCH -name "*.txt" | wc -l) -gt 0 ]; then
    cp *.txt $RUN_DIR_HOME
fi

exit